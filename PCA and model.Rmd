---
title: "PCA and Model Building"
author: "Joy Huang"
date: "October 10, 2018"
output: html_document
---

First of all, import data and all the library I will use in this part.

```{r setup, include=FALSE}
data<- read.csv("C:/Users/joyhu/Dropbox/Summer/New Pro/Innovation/IT.csv")
library(plm)
library(tseries)
library(xts)
library(psych)
library(MASS)
library(sandwich)
library(strucchange)
library(vars)
library(lmtest)
```


###Step0.import the dataset

make transformation(log) on the data to keep them comparable

```{r, echo=FALSE}
data[,-c(1,2,26,27)]<-log(data[,-c(1,2,26,27)])
summary(data)
```

###Step1.preprocessing of the dataset

PCA is a good method in this stage (since the dataset has nearly 30 variables, I think I should do dimension reduction here)
At first I try to divided the variables into three parts according to their meaning, but latter I found there is no need. Because it will not bring any difference to the final result.

```{r, echo=FALSE}
data1<-data[,c(4:25)]
data1.cor<-cor(data1)
test.pr<-princomp(data1,cor=TRUE) 
summary(test.pr,loadings=TRUE)
a1<-summary(test.pr,loadings=TRUE)$loadings

#create a dataframe and store our new variabels
df1<-data.frame(matrix(0,672,9))

for (i in c(1:9)){
  for (j in c(1:22)){df1[,i] = df1[,i]+a1[j,i]*data1[,j]}
}

#just give them a simple and direct name

data.new<-cbind(data[,c(1,2,3,26,27)],df1)
colnames(data.new)<-c("country","year","export","income","OECD","pc1","pc2","pc3","pc4","pc5","pc6","pc7","pc8","pc9")

```

###Step2.Test before building model

ADF test is to exam whether the data stationary on the dataset. If the p-value<0.5, we could conclude that the data is stationary.

```{r,echo=False}
##ADF test- stationary
v <- c(6:14)
a1<- function(x) {
  xts(data.new[,x],as.Date(data.new[,2]))
}
b1<-function(x){
  adf.test(a1(x))$p.value
}
o1<-function(x){
  adf.test(a1(x))$statistic
}

#try to view the result more clearly
m1<-lapply(v,o1)
n1<-lapply(v,b1)
df11 <- data.frame(matrix(unlist(m1), byrow=T))
df12 <- data.frame(matrix(unlist(n1), byrow=T))
q1<-data.frame(df11,df12)
colnames(q1)<-c("test","p.value")
q1
```

Before we start model building, we also should promise there is no multicollinearity problem in the dataset. And same as ADF test, this step is to make sure there is no unreliable regression model built.

```{r,echo=False}
#multicollinearity
cor1<-cor(data.new[,-c(1:5)])
length(which(cor1>0.5))/(nrow(cor1)*ncol(cor1))

library(ggplot2)
library(corrplot)
library(RColorBrewer)
p.mat1<-cor.mtest(data.new[,-c(1:5)])$p
corrplot(cor1, method = "color",
         type = "upper", order = "hclust",tl.cex = 1.5,
         addCoef.col = "black", # Add coefficient of correlation
         tl.col = "black", tl.srt = 60, # Text label color and rotation
         # Combine with significance 
         p.mat=p.mat1, sig.level = 0.01, insig = "blank", number.cex =1.1, pch.col="grey",
         # hide correlation coefficient on the principal diagonal
         diag = FALSE)
library(usdm)
vif(data.new[,-c(1:5)])
vif(data.new[,-c(1:6)])

cor1.1<-cor(data.new[,-c(1:6)])
corrplot(cor1.1, method = "color",type = "upper",
         order = "hclust",tl.cex = 1.5,
         addCoef.col = "black", # Add coefficient of correlation
         tl.col = "black", tl.srt = 60, # Text label color and rotation
         # Combine with significance 
         p.mat=p.mat1, sig.level = 0.01, insig = "blank", number.cex =1.5,
         # hide correlation coefficient on the principal diagonal
         diag = FALSE)
data.new<-data.new[,-6]
```

###Step3.Model Building
After make sure everything is all right, we could finally start model building, I am really exciting to figure out whether PCA will make any difference on the finally result!

```{r,echo=False}
## Model building and set index
form1<- data.new$export~data.new$pc2+data.new$pc3+data.new$pc4+data.new$pc5+data.new$pc6+data.new$pc7+data.new$pc8+data.new$pc9
data.new<-plm.data(data.new,index=c('country','year'))

## Firstly, we compare random effect model and mixed effect model(pool)
#mixed effect model
po<-plm(form1,data=data.new,model='pooling')
#random effect model
re<-plm(form1,data=data.new,model="random")

phtest(po,re)


#Then, get the result of fixed effect model(here siginificant on individual level but not significant on time level)
wi<-pooltest(form1,data=data.new,effect='individual',model='within')
wt<-pooltest(form1,data=data.new,effect='time',model='within')

#compare fixed and random-Hausman Test
phtest(wi,re)

#random-LM
pbgtest(form1,data=rankdata1,model="within")

```


###Step4.Test part

After get our model, we should analysis two things: First is serial correlation (autocorrelation), the other is homoskedasticity, which means the variance of errors are not constant. !!ATTENTION: have to figure out what is the original hyppothesis and what is alternative hypothesis. Here for these two(H0 for Breusch-Godfrey is no serial correlation problem, H0 for Breusch-Pagan is variance constant for each variables's error). The small p-value here means that the model does not pass the hypothesis test and need some exchange.

```{r,echo=False}
#Breusch-Godfrey test
pbgtest(form1,data=data.new,model='within')

#Breusch-Pagan test for homoskedasticity
pwartest(form1,data=data.new)
form1.1 <- data.new$export~data.new$pc2+data.new$pc3+data.new$pc4+data.new$pc5+data.new$pc6+data.new$pc7+data.new$pc8+data.new$pc9+factor(data.new$country)
bptest(form1,studentize=F)

pwtest(form1,data=data.new)
pwfdtest(form1,data=data.new,test='J')
```

###Step5.Modification

Try to add lag item in the dataset to help it pass the test.

```{r,echo=False}
#method 1
form2<- data.new$export~lag(data.new$export,1)+data.new$pc3+data.new$pc4+data.new$pc6+data.new$pc7+data.new$pc8+data.new$pc9
z<-plm(form2,data=data.new,effect="individual",model="within")
pbgtest(form2,data=data.new,model='within')
pwartest(form2,data=data.new)

#method 2
form3<- lag(data.new$export,1)~lag(data.new$pc3,1)+lag(data.new$pc4,1)+lag(data.new$pc6,1)+lag(data.new$pc7,1)+lag(data.new$pc8,1)+lag(data.new$pc9,1)
z1<-plm(form3,data=data.new,effect="individual",model="within")
pbgtest(form3,data=data.new,model='within')
pwartest(form3,data=data.new)

#method 1
form2<- data.new$export~lag(data.new$export,2)+lag(data.new$pc4,1)+lag(data.new$pc6,1)+lag(data.new$pc7,1)+lag(data.new$pc8,1)+lag(data.new$pc9,1)
z2<-plm(form2,data=data.new,effect="individual",model="within")
pbgtest(form4,data=data.new,model='within')
pwartest(form4,data=data.new)
```

The result shows none of them finally pass the test, and after I add lag export into the data, the model became perfectly match, which indicate the lag is not a good variable here( but other could success in this field!! I am really confused about that!)

###Step6.Conclusion

The patent and Government orEudcation spend on GDP may could not affect export on computer composition a lot.